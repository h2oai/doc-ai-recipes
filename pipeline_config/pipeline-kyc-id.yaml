spec: # A general scoring pipeline example that does OCR, token class prediction and page class prediction on a set of data

  pipeline:
    steps:
    - tasks:
       - name: "Intake" # name of task
         type: PipelineTask # if absent, defaults to PipelineTask.  Can also be PipelineReorderInputs and InputCommand.  InputCommand cannot be used in the scorer.
         class: argus.processors.ocr_processors.Intake # fqn_of_Processor class
         parameters:
           #Replace with path to your input docs. Can be relative.
           root_docs_path: .
           follow_symlinks: true
    - tasks:
       - name: "PdfExtract"
         type: PipelineTask 
         class: argus.processors.ocr_processors.PdfTextExtract
    - tasks:
       - name: "ImageNormalize"
         class: argus.processors.ocr_processors.NormalizeImages
         parameters:
           resample_to_dpi: 300 
           normalize_image_format: .jpg
    - tasks:
       - name: "OCR"
         class: argus.processors.ocr_processors.GenericOcr
         parameters:
           ocr_style: E3DocTROcr
    - tasks:
       - name: "Predict_token"
         class: argus.processors.train_eval_processors.TrainEvalProcessor
         parameters:
           predict_only: true
           artifacts:
              base_model_name_or_path: id_card # matches the basename before .zip
    - tasks:
       - name: "Predict_page" 
         class: argus.processors.train_eval_processors.TrainEvalProcessor
         parameters:
           predict_only: true
           artifacts:
              base_model_name_or_path: page_class_model
    - tasks:
       - name: "PostProcess"
         class: argus.processors.post_processors.generic_post_processor.PostProcessor
         parameters:
           output_format: 'json'
           labeling_threshold: 0.2

    #other parameters to the Pipeline constructor go here
    # format: #the format of the intermediate and final (output) annosets.  Defaults to PickleAnnoset.
    #  path: ''
    #  options:
    #    type: PickleAnnotationSet
    # working_dir: /some/path #all relative paths will be relative to this dir, (except output annosets and their root_resource_paths, which are relative to output_dir).  The default working_dir is where the script is executed #all relative paths will be relative to this dir, (except output annosets and their root_resource_paths, which are relative to output_dir)
    #document filtering options
    doc_id_prefix: null #can be /path
    doc_id_prefix_range: null #can be [path, path], python-range style
    filter_ids_file: null #can be path/to/one_doc_name_per_line.txt
    write_all_steps: false #if true, write inner output annosets in pickle format 
    cache_processors: true #if true, cache Processor instances rather than constructing them from scratch for every invocation
    
    artifacts:
    - source: "s3://document-ai-data/test_data/id_card_model.zip"
      name: "id_card"
    - source: "s3://document-ai-data/test_data/page_class_model.zip"
      name: "page_class_model"
